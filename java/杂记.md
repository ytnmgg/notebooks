- [锁](#锁)
  - [synchronized的底层原理](#synchronized的底层原理)
  - [synchronize 和 reentrantLock](#synchronize-和-reentrantlock)
  - [Unsafe.park() 原理](#unsafepark-原理)
  - [JAVA线程六大状态：](#java线程六大状态)
  - [reentrantLock 的 AQS 怎么处理的公平锁和非公平锁：](#reentrantlock-的-aqs-怎么处理的公平锁和非公平锁)
  - [CountDownLatch 的 AQS](#countdownlatch-的-aqs)
- [redis](#redis)
  - [redis 多线程还是单线程](#redis-多线程还是单线程)
  - [bigKey问题：](#bigkey问题)
  - [lua脚本超时：](#lua脚本超时)
  - [redis 分布式锁](#redis-分布式锁)
  - [redis zset 定时关单](#redis-zset-定时关单)
  - [redis限流](#redis限流)
- [库存扣减](#库存扣减)
- [缓存](#缓存)
- [xa 2pc 3pc tcc](#xa-2pc-3pc-tcc)
- [tomcat](#tomcat)
- [ThreadLocal](#threadlocal)
  - [InheritableThreadLocal](#inheritablethreadlocal)

# 锁
## synchronized的底层原理
   https://blog.csdn.net/weixin_42460087/article/details/126474481
   https://www.cnblogs.com/wffzk/p/16639472.html

   锁膨胀流程
   https://blog.51cto.com/u_16099203/7536494

   对象header、mark word、ObjectMonitor对象
   底层依赖操作系统的mutex lock、汇编原子命令xchgb
   https://blog.csdn.net/lengxiao1993/article/details/81568130

## synchronize 和 reentrantLock 
> https://www.zhihu.com/question/57794716/answer/2897302175?utm_id=0

      1. 前者是java内置特性；后者是Java代码实现的
      2. 灵活性后者较大
         1. 前者自动释放；后者手动释放
         2. 前者只能非公平锁；后者可以公平锁
         3. 后者支持超时时间，前者不支持，会一直等待
         4. 后者支持中断
      3. 性能后者好
         1. 早期的 synchronized 实现在并发度较高时性能较差，因为它使用了重量级锁，本质是依赖于底层操作系统的Mutex Lock实现，这会导致在没有竞争的情况下也需要进行操作系统级别的锁操作，需要进行用户态到内核态的切换，这会导致性能下降。挂起线程和恢复线程都需要转入内核态去完成，阻塞或唤醒一个Java线程需要操作系统切换CPU状态来完成，这种状态切换需要耗费处理器时间。
         2. 在上下文切换这一方面，两个锁其实都是要阻塞和唤醒线程，因此都会发生线程的上下文切换，但是 ReentrantLock 通过 CAS 进行优化，在线程阻塞之前，会进行多次 CAS 抢锁操作，不需要进入内核态，因此降低了线程上下文切换的概率。而 synchronized 只要升级为了重量锁，线程来拿锁时一定会进入队列中阻塞等待


## Unsafe.park() 原理

未获取到锁是通过Unsafe.park()接口挂起线程，等待被unpark()方法唤醒。park/unpark的linux底层原理：

在Linux系统下，是用的Posix线程库pthread中的mutex（互斥量），condition（条件变量）来实现的。
- mutex和condition保护了一个_counter的变量，当park时，这个变量被设置为0，当unpark时，这个变量被设置为1。_counter字段，就是用来记录所谓的“许可”的。
- condition条件变量被用来阻塞一个线程，当条件不满足时，线程往往解开相应的互斥锁并等待条件发生变化。一旦其他的某个线程改变了条件变量，
   它将通知相应的条件变量唤醒一个或多个正被此条件变量阻塞的线程，这些线程将重新锁定互斥锁并重新测试条件是否满足。

## JAVA线程六大状态：
   New（新建）
   Runnable（运行态：拿到CPU时间片就是Running、等待CPU调度就是Ready）
   Blocked（阻塞，等待锁释放）
   Waiting（无期限等待，让出CPU资源，等待显式唤醒）
   Timed_Waiting（超时等待，有明确结束时间的等待，比如用sleep方法传入一个要睡眠的时间，时间到了以后线程自己会醒）
   Terminated（终止）

## reentrantLock 的 AQS 怎么处理的公平锁和非公平锁：

      reentrantLock 用的AQS的排它锁（tryAcquire/tryRelease），state有0和1两种状态，但是可重入，同一个线程重复获取锁会将state往1以上自增

      公平锁：先查看队列中有没有排队的线程，没有排队的，才去CAS操作：无锁状态下state=0，CAS加锁尝试将其设置为1；如果有排队的，就将自己加入队尾，挂起当前线程
      非公平锁：上来就CAS，尝试改state，成功就获取锁；不成功就将自己加入队尾，挂起当前线程

## CountDownLatch 的 AQS

      CountDownLatch 用的AQS的共享锁（tryAcquireShared/tryReleaseShared）

      state初始化为count的个数，每一个线程执行countdown，state都减1（调用tryReleaseShared，CAS state，使之减1）
      主线程调用await，实际是调用tryAcquireShared，查看state是否减到0，是的话返回成功继续后续代码；否的话，加入队列挂起主线程，等待唤醒


1. ArrayList和LinkedList区别
   https://cloud.tencent.com/developer/news/700913
   https://blog.csdn.net/qing_gee/article/details/107531949

2. ArrayList非线程安全的解决办法
    https://blog.csdn.net/xsjzn/article/details/124361000

    Collections.synchronizedList()、CopyOnWriteArrayList

3. HashMap的resize流程
   https://blog.csdn.net/cy973071263/article/details/122869909
   https://blog.csdn.net/weixin_39667787/article/details/86678215

4. ConcurrentHashMap CAS+synchronized


2. Spring



# redis
   
## redis 多线程还是单线程
   https://zhuanlan.zhihu.com/p/646111642
   Redis6开始支持多线程：
   1. 主线程处理请求，建立连接获取socket
   2. 主线程将socket分配给多个IO线程并行处理socket，阻塞等待。
   3. 多个IO线程读取socket请求并解析，并行处理完成后返回结果给主线程
   4. 主线程执行命令
   5. 主线程将结果写入输出缓冲区
   6. 主线程阻塞，等待多个IO线程并行回写socket完成。


## bigKey问题：
      1. 影响：
         1. redis处理请求单线程，单个key内容太大，处理变慢，阻塞其它请求
         2. 内存占用过大，有可能被淘汰策略逐出
         3. 大key过期不一定能及时删除，导致内存溢出
         4. 网络带宽占用过大，影响请求速率
         5. 影响主从同步实时性

      2. 解决：拆分、压缩
   
## lua脚本超时：
      如果时长达到 Lua-time-limit（默认5秒）规定的最大执行时间，Redis只会做这几件事情：
         - 日志记录有脚本运行超时
         - 开始允许接受其他客户端请求，但仅限于 SCRIPT KILL 和 SHUTDOWN NOSAVE 两个命令
           - SCRIPT KILL：停止脚本，但是脚本里有写命令的话，这个请求会失败
           - SHUTDOWN NOSAVE：停止redis服务器，防止。这里也说明：AOF文件是在整个lua脚本的命令都执行完成以后，再刷盘AOF文件的
         - 其他请求仍返回busy错误
      
      为什么服务器不强制停掉脚本的执行？担心原子性，中途停止可能导致内存的数据集上只修改了部分数据（只读脚本可以正常停止）



## redis 分布式锁
   https://blog.csdn.net/scm_2008/article/details/127422698

      3. 普通： setnx key value 返回1成功，0失败； del key 释放锁
      4. 解决服务宕机，无法释放：setnx key value; expire key 60
      5. 2中两条命令不是原子的，还是有可能执行了setnx之后没来得及执行expire就宕机了，解决方式是用lua脚本保障原子性：
          String lua_scripts = "if redis.call('setnx',KEYS[1],ARGV[1]) == 1 then redis.call('expire',KEYS[1],ARGV[2]) return 1 else return 0 end";
          jedis.eval(lua_scripts, key, value, 60);
      6. redis2.6开始支持原子命令：set key value ex 60 nx
      7. del key 可能误删别人的（场景：线程1拿锁执行业务，超过了expire时间，锁自动释放；线程2拿到锁，正在进行业务；线程1执行完成业务，删锁，实际上是线程2的锁被释放了；线程3过来又拿到了锁，和线程2同时进行业务，资源冲突）
      8. 5的解法：value中保存线程唯一id，线程去解锁的时候，判断id是否一致（是否不是自己的锁），再决定是否删除
      9.  6又出现了原子性，get id和del key不是原子的，又得用lua脚本保障原子性：
         String lua_scripts = "if (redis.call('get', KEYS[1]) == ARGV[1] ) then redis.call('del', KEYS[1]); return 1; end; return 0;";
         jedis.eval(lua_scripts, key, value);

## redis zset 定时关单
      10. zadd key score value : key=表名，score=单据应该过期的时间戳（创建时间+过期间距），value=单据id
      11. zrangebyscore key min max withscores LIMIT offset count: 
         min=0，max=当前时间戳，则过期时间小于当前时间的单据都能捞出来，offset=0 count=100：一次从头捞100个
      12. zrem key value: 执行业务单据过期操作以后，删除value=id的reids记录 
         或者批量删：zremrangebyscore key min max
      注意上面2~3步骤，需要加分布式锁

## redis限流
      方法1：zset时间窗
      13. 访问一次就添加一条记录：zadd key score value: key=uid, score=当前时间戳，value=当前时间戳
      14. 删除时间窗口外面的记录：zremrangebyscore key min max: key=uid, min=0, max=当前时间戳-窗口大小（比如：1000=1秒）
      15. 统计窗口内的条数：zcard key: key=uid，判断count和限流值大小关系，决定是否丢弃当前请求

      方法2：incr and expire
      https://redis.com/glossary/rate-limiting/
      16. get key: key=uid:minute，即key由uid+当前分钟数组成，比如xxxx:3，表示xxxx用户第3分钟的访问次数
      17. 如果值存在，且大于限流值，比如20，则抛限流异常
      18. incr key; expire key 59： 加一，且1分钟后过期
         注意：上面方法，incr key，如果key不存在，那么key的值会先被初始化为0，然后再执行 INCR 操作，即始终会设置值为1，不会报错

      方法3：令牌桶
      令牌桶和漏捅区别：

      瞬时速率：如果在一瞬间有很多请求进来，此时来不及产生令牌，则在一瞬间最多只有n个请求能获取到令牌执行业务逻辑，所以令牌桶算法也可以控制瞬时速率
               漏桶由于出水量固定，所以无法应对突然的流量爆发访问，也就是没有保证瞬时速率的功能，但是可以保证平均速率
      场景：漏桶更适用于“秒杀、抢购、热点时间”等场景，因为这种场景用漏桶的话是先缓存请求，但是令牌桶则是先丢弃请求，会造成大量报错

      lua 脚本:
      ```lua
         local current_time=tonumber(ARGV[1]) -- 当前时间（毫秒时间戳）
         local capacity = 100   -- 桶容量，也作为每秒生成token的个数，即QPS
         local required_amount = 1  -- 单次取几个

         -- 当前令牌数
         curr_amount = redis.call('get', 'bucket_limit')
         -- 下一次有token可用的时间（毫秒时间戳）
         next_time = redis.call('get', 'next_time')

         -- 情况一：桶不存在、或者过期，重新生成桶和过期时间，且返回未限流结果
         if (curr_amount==false or last_time==false) then
            redis.call('set', 'bucket_limit', capacity - required_amount, 'EX', 60)
            redis.call('set', 'next_time', current_time, 'EX', 60)
            return 0 -- 未触发限流
         end

         -- 情况二：触发限流判断：还没到下一次有token可用的时间
         if (next_time > current_time) then
            return 1 -- 触发限流
         end

         -- 情况三： 未触发限流，更新token数量和下一次有token可用的时间
         -- 根据和上一次时间比较，更新生成新的token
         interval = 1000 / capacity -- token生成间隔（毫秒），capacity是每秒token数，则1000/capacity就是产生两个token之间的时间间隔
         created_amount = (current_time - next_time) / interval
         new_amount = curr_amount + created_amount
         if (new_amount > capacity) then
            curr_amount = capacity
         else
            curr_amount = new_amount

         -- 减去这次需要的token，更新剩余token和下一次有token可用的时间
         need_amount = 0
         if (curr_amount < required_amount) then
            need_amount = required_amount - curr_amount -- 距离需要的token数量，还差几个
         else
            curr_amount = curr_amount - required_amount -- 还剩几个
         end

         wait_time = need_amount * interval -- 距离需要的token数量，还需要等多久
         next_time = current_time + wait_time -- 下一次有token可用的时间（毫秒时间戳）

         redis.call('set', 'bucket_limit', curr_amount, 'EX', 60)
         redis.call('set', 'next_time', next_time, 'EX', 60)

         return 0 -- 未触发限流 

      ```

# 库存扣减
    现状：
    目前单热点3000tps，单分片6000tps （当前最高可放开至单热点6000tps，单分片10000tps）
    提高性能措施：
    1. 业务上单个活动用多个库存id，业务均衡到不同的库存id，然后某个扣减完毕后，更新本机查询缓存，并路由到下一个id去做扣减
    2. 缓存，分批去db拿额度，比如总10w，每次拿1k，根据消耗量监控，自动决定消耗率（tps）低于多少以后，退回去，直接去db拿。

   目标： 50w
   方案：
   主子库存
      创建：从主库存分配若干到子库存
      追加：追加到主库存
      扣减：
         正常模式：主分配部分到子，每个子可以互相路由，最后到主；子低于阈值后可以找主再分配库存
            服务维护路由表，路由表保存在redis，优先去本zone，没有之后去其它zone（没有的时候，还要更新路由表本zone状态，让其他zone别来），最多路由3个，就去主库存了，保存路由结果，下次就直接去新的zone，除非新zone又没有了后更新状态，或者追加子库存后的更新状态。
         秒杀模式：主一次性分配到子，每个子不路由，没有了就报错无库存
      回收：子库存低于阈值，或手动触发，锁子库存，减子库存，加主库存
      再分配：从主库存分配若干到子库存，由子库发起，子库不够（水位线：步长的5%）了，找主库申请步长（主预算的30%/分桶数量）的库存
      库存余额查询：定时任务汇总，更新到redis

   异步化扣减：只在本zone记流水记录，不去扣减库存库
   前提：库存余额水位充足（大于30%），能够支持峰值qps（比如6k/s）扣减一段时间

   缓冲记账：先insert流水，再异步汇总扣余额，当余额到达一定阈值后，变成实时记账（或告警）：还是有多扣风险
   缓存记账：扣减放到缓存里面，缓存有热点问题，比OB好不了多少，还是得做拆分（主子库存）解决问题

# 缓存
    1. 删除缓存优于更新缓存
       1.1 缓存内容有时候结构比较复杂，是一堆东西的汇总，遍历更新代码更复杂，删操作更轻量
       1.2 删除是一个lazy Loading的思想，用到缓存了再更新并缓存；否则极端场景，读比较少，修改了100次db，要改100次缓存，但是恰好缓存只读了1次。。99次更新缓存都是废操作
       1.3 一致性问题：
         同时有请求A和请求B进行更新操作，那么会出现
         （1）线程A更新了数据库
         （2）线程B更新了数据库
         （3）线程B更新了缓存
         （4）线程A更新了缓存
         这就出现请求A更新缓存应该比请求B更新缓存早才对，但是因为网络等原因，B却比A更早更新了缓存。这就导致了脏数据，因此不考虑。
         当然加分布式锁可以解决这个问题，但是比较起来，删除操作就简单很多了。
   2. 先删缓存，再更新db
      (1) 线程A删缓存
      (2) 线程B读缓存，没命中
      (3) 线程B读db，更新缓存为值10 （此时缓存为旧值）
      (4) 线程A更新数据库为20 （出现新值与缓存值不一致！）
   3. 先更新db，再删缓存
      (1) 线程A读取缓存，恰好缓存失效，查db，得旧值10
      (2) 线程B更新db为新值20，再删缓存
      (3) 线程A拿到旧值10，回写缓存10（出现新值与缓存值不一致！）
   4. 延迟双删
      （1）先淘汰缓存
      （2）再写数据库（这两步和原来一样）
      （3）休眠1秒，再次淘汰缓存

            为什么要延迟：
               这里4-(3)，是指在上面《先删缓存，再更新db》的2-(4)后面加一步:
                  2-(5)线程A去做缓存删除。
               这里延迟的目的是想等其它读到db旧值的线程，回去更新缓存都结束了，这里删除之后，线程去db拿一定是拿新值，再把新值更新到缓存。
               》》》即db数据已经落库完成了，且之前拿到旧值的数据都回来了，不会再有旧值干扰设置到缓存了《《《
               
            1秒怎么定？在读数据业务逻辑的耗时基础上，加几百ms即可。这么做的目的，就是确保读请求结束，写请求可以删除读请求造成的缓存脏数据。
               》》》因为在db新数据落库完成之前的0.0001s，又来了一个请求，拿到旧数据，慢慢回去，得等这个请求完成之后，再删缓存《《《

# xa 2pc 3pc tcc
   XA: Oracle 提出的 XA分布式事务协议。XA协议包括两阶段提交（2PC）和三阶段提交（3PC）两种实现
   2PC: prepare、commit/rollback
   3PC: canCommit、preCommit、doCommit
      3PC相较于2PC：
         1. canCommit不占用资源，只是轻量的预检查，降低了阻塞时间（2PC的prepare就要占用资源）
         2. 解决2PC协调者的单点故障，参与者等待preCommit或者doCommit的时候有超时机制，参与者等待协调者超时，自动abort
   TCC: 类似2PC，2PC是数据库层面的底层实现，TCC是应用层面的分布式事务，需要编写业务代码实现2PC的流程：Try、Confirm、Cancel

   14.1 TCC空提交、空回滚、悬挂
      拒绝空提交、允许空回滚：没有一阶段锁定资源，二阶段空提交是严格不允许的；空回滚对业务无影响，允许空回滚；
      空回滚：一阶段prepare请求超时、丢包，协调者没收到响应，对参与者发起回滚；参与者角度看，没收到一阶段，直接来了二阶段，这种情况允许回滚操作，即空回滚。
      悬挂：二阶段空回滚过后，一阶段请求因为超时，晚于一阶段请求到来，由于永远等不到二阶段请求了（协调者已经发起事务回滚了），导致这个迟到的一阶段请求无法推进，即悬挂。

      实际中，空回滚一般是由于参与者数据库hang住了，导致一阶段处理超时，协调者发起回滚，参与者拿到回滚请求，查询一阶段数据，因为一阶段请求没写进db，导致认为一阶段没有进行就来二阶段了，于是进行空回滚操作。

      悬挂中的二阶段，如果遇到同一个事务的重试，有可能被提交两次，导致资损。

      实际中的防悬挂方案：双插 防悬挂记录（唯一键: 主事务号+分支事务号）
         1. 一阶段来了插入一条防悬挂记录（不加锁，直接插入），
            1.1 插入成功进行业务逻辑；
            1.2 插入失败检查记录，发现已经插入过,加锁并判断
              1.2.1 查看状态，是一阶段插入的状态（I），则执行幂等业务逻辑
              1.2.2 查看状态，是二阶段回滚插入的状态（R），则拒绝提交，这里就防止了悬挂记录的插入
         2. 二阶段来了，查看是否有防悬挂记录
            2.1 发现有的，加锁并判断：
              2.1.1 状态I的表示一阶段插入的，执行正常回滚操作
              2.2.2 状态R的表示之前回滚插入的，可能是重试，也允许回滚
            2.2 如果没有记录，则插入一条回滚记录（状态R），进行空回滚。


# tomcat
    1. 连接数、线程数：
   https://www.cnblogs.com/kismetv/p/7806063.html

   maxConnections：默认值与连接器使用的协议有关：NIO的默认值是10000，，而BIO的默认值为maxThreads
   acceptCount：队列长度，默认100
   maxThreads: 最大线程数，默认设置 200，一般建议在 500 ~ 1000，根据硬件设施和业务来判断
   minSpareThreads: 核心线程数，默认设置 25
   prestartminSpareThreads: 在 Tomcat 初始化的时候就初始化核心线程
   maxQueueSize: 最大的等待队列数，超过则拒绝请求 ，默认 Integer.MAX_VALUE

   有时候我们通常会认为在默认配置下，最大并发量就是最大连接数，
   超过最大连接数10000后会出现tomcat拒绝连接的情况，
   触发的请求任务超过默认值200(最大线程数)+默认值100(等待队列长度)后，tomcat会拒绝处理请求任务

   最大并发量，每个人都它的理解是不一样的：
   - 如果在乎tomcat运行能够同时处理的任务数量，那最大并发量可能理解成最大工作线程数(max-threads)---不包含队列里的数量(acceptCount)
   - 如果在乎tomcat运行能够接纳的最大最多的任务数量，那最大并发量可以理解成最大连接数(max-connections)+队列长度的数量(accept-count) --- 包含队列里的数量(acceptCount)


# ThreadLocal
Thread 持有 ThreadLocal.ThreadLocalMap

ThreadLocalMap 持有 Entry[] 数组
数组内容是ThreadLocal持有的内容
数组下标定位是通过ThreadLocal对象求hash后定位的

也就是，一个Thread有多个ThreadLocal，每个ThreadLocal对象求hash计算得一个下标i，
则Entry[i]就是第i个ThreadLocal对象里面保存的业务内容

ThreadLocal的get和put，就是去当前Thead持有的ThreadLocalMap里面去存取内容。

## InheritableThreadLocal
重写了ThreadLocal的三个方法：childValue，createMap，getMap
使用的是Thread持有的 inheritableThreadLocals

Thread初始化创建的时候，检查父线程的 inheritableThreadLocals 是否已经存在，如果有的话，直接复制过来。

这样子线程就继承了父线程的ThreadLocal了。