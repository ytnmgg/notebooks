- [架构](#架构)
  - [S.O.L.I.D设计原则](#solid设计原则)
  - [常见原则：](#常见原则)
  - [好的架构：](#好的架构)
- [安全：](#安全)
- [其它](#其它)
  - [网站如何支持cname自定义域名的https证书的](#网站如何支持cname自定义域名的https证书的)
  - [SQL](#sql)
- [BPMN（Business Process Model and Notation）标准](#bpmnbusiness-process-model-and-notation标准)
  - [BPMN 2.0 的元素包括五种类型](#bpmn-20-的元素包括五种类型)
- [容量](#容量)
  - [营销容量](#营销容量)
  - [中间件容量](#中间件容量)
- [资金安全](#资金安全)
- [高可用](#高可用)
  - [三地五中心（用于存全局数据，比如账户余额等）](#三地五中心用于存全局数据比如账户余额等)
  - [流水型failover（用于用户维度的数据，比如支付单）](#流水型failover用于用户维度的数据比如支付单)
- [高并发](#高并发)
  - [缓存](#缓存)
- [人群](#人群)
- [连接池](#连接池)
- [msgBroker](#msgbroker)
  - [10s的消费限时](#10s的消费限时)
  - [xxKB 消息体大小限制](#xxkb-消息体大小限制)
  - [msgBroker和rocketMq区别：](#msgbroker和rocketmq区别)
- [库存扣减](#库存扣减)
- [xa 2pc 3pc tcc](#xa-2pc-3pc-tcc)
- [cap](#cap)
  - [一般P一定要满足](#一般p一定要满足)
- [配置中心，实时推送原理](#配置中心实时推送原理)
  - [实际流程：](#实际流程)
- [tomcat](#tomcat)
  - [tomcat 支持几种连接方式](#tomcat-支持几种连接方式)
- [zookeeper](#zookeeper)
  - [利用zk实现高可用java集群](#利用zk实现高可用java集群)
- [raft](#raft)
  - [raft优化](#raft优化)
  - [raft安全性](#raft安全性)
  - [raft 与 zab](#raft-与-zab)
    - [相同](#相同)
    - [不同](#不同)
- [encoding: utf-8](#encoding-utf-8)
- [str = raw\_input("please input a number:")](#str--raw_inputplease-input-a-number)


# 架构
   
## S.O.L.I.D设计原则
- 单一职责原则（Single Responsibility Principle）
   - 模块功能单一，反之如果模块承担的职责过多，就等于把这些职责耦合在了一起，某一个职责的变化就可能影响该模块完成其他职责的能力。
- 开放封闭原则（Open-Closed Principle）
   - 面向扩展开放，面向修改封闭。
- 里式替换原则（Liskov Substitution Principle）
   - 子类可以扩展父类的功能，但一定要具备完整父类等能力。否则在抽象类中进行的模版方法，一般是针对父类不识别子类的，这些方法将运行失败。
- 接口隔离原则（Interface Segregation Principle）
   - 模块只应依赖于它需要的接口，而不依赖于不需要的接口。这意味着我们应该尽量将接口拆分为更小、更具体的接口，以避免客户端使用不需要的方法。
   - 软件设计如果依赖了它并不需要的东西，就会带来意料之外的麻烦
- 依赖反转原则（Dependency Inversion Principle）
   - 依赖反转原则要求我们依赖于抽象而不是具体实现。这意味着我们应该通过接口或抽象类与外部组件进行交互，而不是与具体的实现类直接进行交互。
   - 我们应该面向接口编程。通过抽象成接口，使各个类的实现彼此独立，实现模块之间的松耦合。
   -  https://blog.csdn.net/lijingronghcit/article/details/107898782

   
## 常见原则：
分层架构、模块化设计、高内聚低耦合、SOLID原则

## 好的架构：
- 易于理解和维护
  - 分层架构，模块化设计
  - 模块高内聚低耦合
  - 核心逻辑对应用层透明
- 可重用可扩展
  - 核心领域模型抽象合理
  - 模块职责单一，减少重复劳动
  - 面向接口编程（SOLID）
  - 具备技术前瞻性
- 模块、系统间交互合理（API、SPI、消息）
- 高可用、高性能、安全


# 安全：
   认证、授权、内容篡改等风险
   数据泄露风险（包括敏感数据泄露风险）
   业务漏洞（参数验证）
   
   XSS跨站脚本攻击、恶意SQL注入风险 
    1. MyBatis启用了预编译流程，先将写的sql编译（sql注入的语句没参与编译，不能执行），再把输入的变量值拿去替换编译后语句中的问号占位符
    2. 但是mybatis语句中要用#{xxx}，不要用${###}，因为前者是会当做字符串，要加引号，可以防注入；后者直接是字符串拼接，可能注入
    3. mybatis预编译时，会把${xxx}(已注入的语句)一起进行编译，所以无法防注入；但是#{xxx}会用问号替换，进行编译，完成之后再把输入内容替换掉问号，所以能防止注入
   CSRF跨站请求伪造风险
   限流、降级、拉黑措施

   DDOS、DNS劫持


# 其它
## 网站如何支持cname自定义域名的https证书的
    https://zhuanlan.zhihu.com/p/547260827
    SNI (Server Name Indication) 是 SSL/TLS 协议的一个扩展，与HTTP Host头类似；
    如果握手时不携带SNI，则无法判断该HTTPS请求的具体身份，只能返回默认证书，因此一个服务端只能支持一张证书；
    在支持SNI扩展之后，服务端可以支持多证书，服务端根据请求的SNI，选择返回网站自己的证书，还是用户CNAME的自定义证书。

    nginx如何动态处理证书：
        ng配置里面加上lua脚本：ssl_certificate_by_lua_file conf/xxx.lua;




## SQL
   3.1 有一课程表 c_table，有c_no, uid 两个字段，表示课程号和学生id；查选课人数最多的课程no
   ```sql
   select s.cnt, s.nu from(select count(*) as cnt, c_no as nu FROM c_table group by nu) as s
    having s.cnt = (
                    select max(cnt) from(select count(*) as cnt, c_no as nu FROM c_table group by nu)
                )
   ```


# BPMN（Business Process Model and Notation）标准

> https://www.bpmn.org/

## BPMN 2.0 的元素包括五种类型

- 流对象（Flow Objects）：流对象是定义业务流程的主要图形元素。流对象包括：
  - 事件（Events）事件分为：
    - 开始事件(Start)
    - 中间事件(Intermediate，比如消息事件、定时器事件等)
    - 结束事件(End)
  - 活动（Activities）活动分为：
    - 任务（Task）
    - 子流程（Sub Process）
  - 网关（Gateways）网关分为：
    - 排它网关（只有一条路径会被选择）
    - 并行网关（所有路径会被同时选择）
    - 相容网关（可以同时执行多条线路，也可以在网关上设置条件）
- 数据（DATA）：数据描述流程活动之间交换的数据。数据包括：
  - 数据对象（Data Objects）
  - 数据输入（Data Inputs）
  - 数据输出（Data Outputs）
  - 数据仓库（Data Stores）
- 连接对象Connecting Objects）连接对象建立流对象和其他对象的连接。连接对象包括：
  - 顺序流（Sequence Flow）
  - 消息流（Message Flow）
  - 关联（ Association）
  - 数据关联（Data Association）
- 泳道（Swimlane）：泳道用于对流程元素进行分组。泳道包括泳池和泳道两种。
- 制品（Artifacts）：制品用于提供附加信息。制品包括分组和注释两种。


# 容量
## 营销容量
- PV/UV：千万～几亿
- QPS（常/峰）：5k～2w / 100w
- 券咨询（常/峰）：几k / 30w 
- 营销发奖（常/峰）：几百 / 3w
- 单机：300～1k
- 预算库：单热点 3k～6k tps；单分片 6k～1w tps 

## 中间件容量
- redis 10w qps 100w 连接
- nginx 10w qps
- mysql（8核32G） 2w qps，2k～3k tps，1.2w iops，8k连接数
- springboot：2k～7k
- tomcat：默认最大线程数 200；最大连接数：NIO的默认值是10000，BIO的默认值为最大线程数

# 资金安全
- 开发前：领域模型和外围依赖设计；订单、资金的全生命周期（包括正向、逆向）推演
- 开发中：防御式编程；单据幂等设计；消息重试逻辑；事务一锁二判三更新；异常处理检查；数字单位和精度；外围接口幂等及异常推演。
- 上线后：核对；监控；报警；


# 高可用
- 集群架构：容灾备份、切换
- 容量预估：提前压测摸底摸高
- 限流、容的、降级、兜底
- 监控预警
- 预案演练

## 三地五中心（用于存全局数据，比如账户余额等）

城市SH、城市HZ、城市SZ ，SH和HZ互相延迟5ms左右，与SZ延迟30ms左右
raft 5副本，SH=2，HZ=1，SZ=2

SH的账户操作同步到多数，需要忍受到HZ的5ms
SZ的账户操作同步到多数，需要忍受到HZ到30ms

## 流水型failover（用于用户维度的数据，比如支付单）
<注意：mysql才有这个方案，ob天然分片，无需这个>

需要解决两个问题
- 流水产生时，该笔流水应该落到哪个库
- 查询流水时，该去哪个库查流水

解决方案：
- 单据号上加failover库信息，可以根据单据号路由到原主库还是failover库
- 每个rzone，都有互备的failover zone
- 账号拉黑，把不可用范围从库维度缩小到部分账号维度。拉黑故障发生前短时间在主库有过变更的账号，因为无法确认这批账号的变更是否已经同步到备库。数据库恢复之前，禁止这些账号变更，防止资损。实际中可以缩小到几十或几百个账号的范围。

# 高并发
- 分布式架构，集群负载均衡，LDC路由
- 瓶颈处理：数据库的瓶颈，缓存、分库分表、读写分离
- 异步化：消息队列等，提高系统吞吐量、接口响应速度
- 预热：缓存预热、前端资源预加载
- 代码优化：减少循环、递归层数；减少锁粒度等。



## 缓存
三级缓存
- 本机常驻缓存 + 本机LRU
  - 常驻内容来源于离线任务统计的热点数据，属于集群纬度的热点
  - LRU是本机常用的数据，属于单机纬度的热点
  - 上面两个维度结合，效果更好
- 远端 Redis
- 远端 DB

# 人群

- 大人群（百万～千万）：用hbase
  - rowkey=md5(uid)[0:4] + uid + 大场景码；
  - 列族：f 固定
  - 列：小场景id
  - 列值：人群id列表
- 小人群（万级别）：直接查db
  - 先用布隆过滤器过滤（放到blob类型里面（几k到几十M），blob上限4GB）
  - 缓存id：人群id
  - 缓存值：布隆filter对象（从db反序列化到内存，用ObjectInputStream读Byte数组）
  - 验证值：uid

# 连接池

- DAO平均时延10ms，则一个连接每秒可以处理 1000/10 = 100 个DAO动作
- 大促按10倍流量估计，DAO峰值为20w，目前集群机器200台，则单机每秒需要处理的DAO操作数为：20w/200 = 1000 个
- 则单机需要的最大连接数为：1000/100 = 10 （最大连接数设置为10）

或者
- 假设每个sql耗时10ms，则1秒可以跑100个sql；10个连接每秒可以跑100*10=1000个sql，即单机qps=1000

> 知识点：最大连接数：mysq=1w ob=5w

# msgBroker

## 10s的消费限时
所以收到消息后最好只落单据，长耗时任务（比如下游调用）交给定时任务捞异步做

遇到过的问题：
某个批量任务耗时较长，导致消息超时重投，业务上幂等没做好，导致同一单据重复处理。

## xxKB 消息体大小限制
所以消息体尽量使用业务id等关键信息，业务内容走查询逻辑

## msgBroker和rocketMq区别：
- m推，r拉
  - 推模式实时性看起来比拉模式高
  - 拉模式吞吐比推模式更高（每次成批获取消息）
- m用db存储，r用分布式文件系统存储，可靠性前者好
- m性能一般，尤其是抗积压能力不高（百万级别），r性能好，抗积压能力强（亿级别）



# 库存扣减
    现状：
    目前单热点3000tps，单分片6000tps （当前最高可放开至单热点6000tps，单分片10000tps）
    提高性能措施：
    1. 业务上单个活动用多个库存id，业务均衡到不同的库存id，然后某个扣减完毕后，更新本机查询缓存，并路由到下一个id去做扣减
    2. 缓存，分批去db拿额度，比如总10w，每次拿1k，根据消耗量监控，自动决定消耗率（tps）低于多少以后，退回去，直接去db拿。

   目标： 50w
   方案：
   主子库存
      创建：从主库存分配若干到子库存
      追加：追加到主库存
      扣减：
         正常模式：主分配部分到子，每个子可以互相路由，最后到主；子低于阈值后可以找主再分配库存
            服务维护路由表，路由表保存在redis，优先去本zone，没有之后去其它zone（没有的时候，还要更新路由表本zone状态，让其他zone别来），最多路由3个，就去主库存了，保存路由结果，下次就直接去新的zone，除非新zone又没有了后更新状态，或者追加子库存后的更新状态。
         秒杀模式：主一次性分配到子，每个子不路由，没有了就报错无库存
      回收：子库存低于阈值，或手动触发，锁子库存，减子库存，加主库存
      再分配：从主库存分配若干到子库存，由子库发起，子库不够（水位线：步长的5%）了，找主库申请步长（主预算的30%/分桶数量）的库存
      库存余额查询：定时任务汇总，更新到redis

   异步化扣减：只在本zone记流水记录，不去扣减库存库
   前提：库存余额水位充足（大于30%），能够支持峰值qps（比如6k/s）扣减一段时间

   缓冲记账：先insert流水，再异步汇总扣余额，当余额到达一定阈值后，变成实时记账（或告警）：还是有多扣风险
   缓存记账：扣减放到缓存里面，缓存有热点问题，比OB好不了多少，还是得做拆分（主子库存）解决问题


# xa 2pc 3pc tcc
   XA: Oracle 提出的 XA分布式事务协议。XA协议包括两阶段提交（2PC）和三阶段提交（3PC）两种实现
   2PC: prepare、commit/rollback
   3PC: canCommit、preCommit、doCommit
      3PC相较于2PC：
         1. canCommit不占用资源，只是轻量的预检查，降低了阻塞时间（2PC的prepare就要占用资源）
         2. 解决2PC协调者的单点故障，参与者等待preCommit或者doCommit的时候有超时机制，参与者等待协调者超时，自动abort
   TCC: 类似2PC，2PC是数据库层面的底层实现，TCC是应用层面的分布式事务，需要编写业务代码实现2PC的流程：Try、Confirm、Cancel

   14.1 TCC空提交、空回滚、悬挂
      拒绝空提交、允许空回滚：没有一阶段锁定资源，二阶段空提交是严格不允许的；空回滚对业务无影响，允许空回滚；
      空回滚：一阶段prepare请求超时、丢包，协调者没收到响应，对参与者发起回滚；参与者角度看，没收到一阶段，直接来了二阶段，这种情况允许回滚操作，即空回滚。
      悬挂：二阶段空回滚过后，一阶段请求因为超时，晚于一阶段请求到来，由于永远等不到二阶段请求了（协调者已经发起事务回滚了），导致这个迟到的一阶段请求无法推进，即悬挂。

      实际中，空回滚一般是由于参与者数据库hang住了，导致一阶段处理超时，协调者发起回滚，参与者拿到回滚请求，查询一阶段数据，因为一阶段请求没写进db，导致认为一阶段没有进行就来二阶段了，于是进行空回滚操作。

      悬挂中的二阶段，如果遇到同一个事务的重试，有可能被提交两次，导致资损。

      实际中的防悬挂方案：双插 防悬挂记录（唯一键: 主事务号+分支事务号）
         1. 一阶段来了插入一条防悬挂记录（不加锁，直接插入），
            1.1 插入成功进行业务逻辑；
            1.2 插入失败检查记录，发现已经插入过,加锁并判断
              1.2.1 查看状态，是一阶段插入的状态（I），则执行幂等业务逻辑
              1.2.2 查看状态，是二阶段回滚插入的状态（R），则拒绝提交，这里就防止了悬挂记录的插入
         2. 二阶段来了，查看是否有防悬挂记录
            2.1 发现有的，加锁并判断：
              2.1.1 状态I的表示一阶段插入的，执行正常回滚操作
              2.2.2 状态R的表示之前回滚插入的，可能是重试，也允许回滚
            2.2 如果没有记录，则插入一条回滚记录（状态R）进，行空回滚。

# cap
电商保 AP；金融保 CP

## 一般P一定要满足
一般分布式系统，同一个服务部署多台机器，每个机器单独对外提供服务，互相不受影响。这个是高可用、高并发的天然基础能力。
如果出现分区，就不能对外服务了，这个是不能接受的。
这种情况在一般分布式系统也基本不会出现，因为上面说了，现在分布式系统设计，为了高可用、高并发，各个机器独立对外服务，是互相不影响的。
另外，P一定要保证的原因是，我们做不到分布式系统节点间的网络永远不出故障，
现实中，我们面对的是一个不可靠的网络，每个设备都有可能宕机，这两个因素都可能导致 partition，因而分布式系统中，P是必选项。

# 配置中心，实时推送原理
websocket http2.0 等都行
实际：http1.1长连接 servlet3.0异步servlet（tomcat7.0） servlet3.1非阻塞IO（tomcat8.0）
原因：websocket不是http标准协议，应用范围有限；http2.0还没出来；所以选择了http1.1的长连接实现

- http1.0：短连接，浏览器和服务器每次请求都建立新的连接，请求返回连接就结束
- http1.1: 长连接，客户端和服务器的header都需要设置 Connection:keep-alive 
- http2.0: 服务端推送，服务器可以在客户端请求之前，主动向客户端推送数据。
- websocket: 握手用了http协议，连接后的通信是完全不同于http协议的，长连接的，客户端和服务端可以双向通信

servlet比较：
- 同步servlet：业务处理会一直占用servlet线程，直到请求处理完毕这个线程才会释放
- 异步servlet：构造asyncContext，servlet线程退出，回收到线程池继续接受新请求；业务线程从asyncContext中获取request和resoponse处理请求，完成后返回
   即：servlet线程和业务线程隔离，servlet线程提前退出，业务线程接着处理，大大提高了请求吞吐能力。
- servlet3.1 非阻塞IO，NIO，多路IO复用，有IO事件以后，再起servlet线程处理请求。

## 实际流程：
http1.1长连接
- sdk和server建立连接，30s超时，如果server配置无变化，中间不返回东西，30s超时后返回
- sdk 在30s超时后，再次发起请求，进入下一个30s的长连接
- server在30s内发现配置变更，提前返回变化消息（key）给sdk，提前结束30s的长连接状态。
- sdk 收到内容变化的key，再次请求server，获取变化key对应的具体内容；然后再次发起30s的长连接。


# tomcat
    1. 连接数、线程数：
   https://www.cnblogs.com/kismetv/p/7806063.html

   maxConnections：默认值与连接器使用的协议有关：NIO的默认值是10000，，而BIO的默认值为maxThreads
   acceptCount：队列长度，默认100
   maxThreads: 最大线程数，默认设置 200，一般建议在 500 ~ 1000，根据硬件设施和业务来判断
   minSpareThreads: 核心线程数，默认设置 25
   prestartminSpareThreads: 在 Tomcat 初始化的时候就初始化核心线程
   maxQueueSize: 最大的等待队列数，超过则拒绝请求 ，默认 Integer.MAX_VALUE

   有时候我们通常会认为在默认配置下，最大并发量就是最大连接数，
   超过最大连接数10000后会出现tomcat拒绝连接的情况，
   触发的请求任务超过默认值200(最大线程数)+默认值100(等待队列长度)后，tomcat会拒绝处理请求任务

   最大并发量，每个人都它的理解是不一样的：
   - 如果在乎tomcat运行能够同时处理的任务数量，那最大并发量可能理解成最大工作线程数(max-threads)---不包含队列里的数量(acceptCount)
   - 如果在乎tomcat运行能够接纳的最大最多的任务数量，那最大并发量可以理解成最大连接数(max-connections)+队列长度的数量(accept-count) --- 包含队列里的数量(acceptCount)

## tomcat 支持几种连接方式
- 8.0之前BIO，同步阻塞，一个线程对应一个客户端连接
- 8.0之后NIO，同步非阻塞，一个线程做多路IO复用，有IO事件以后，起线程处理
- APR，同步非阻塞，以JNI的形式调用Apache Http服务器的动态链接库。
  - 优势：C语言实现的，操作系统级别的api；直接内存技术，避免jvm的堆内存和系统空间内存拷贝


# zookeeper

## 利用zk实现高可用java集群

- 多个java实例去竞争创建同一个临时节点，只有一个成功，节点内容存当前java实例的地址：create -e /node 192.168.0.3
- 其他未竞争到节点的java实例，注册监听这个节点的变更事件
- 客户端读取该zk的节点，拿到服务地址：get /node，即获取到服务ip，使用该服务
- 竞争到临时节点的java实例挂掉，临时节点会被zk自动删除，其他java实例监听到事件，再次竞争创建临时节点，客户端也可以监听事件，更新客户端缓存的节点内容（服务ip地址）


# raft

## raft优化
官方：candidate的随机选举超时时间（150～300ms）到来后，会提升任期term，再次发起新的选举。（超时原因是没有candidate能拿到多数选票）
改进：给每个candidate赋予全局优先级，收到投票后广播自己得到的票数，如果出现两个candidate票数一样，且最接近超半数票（比如5个node，某几个node都得到2票），优先级高的成为leader（传统方式需要发起新一轮选举）


## raft安全性
- 投票的时候，如果我的日志比你的新，我就不投票给你。新：任期号大的为新；任期号相同，日志号大的为新。
- 新leader从老leader获取的未提交的日志（老leader复制日志到follower，提交之前down机了），只会将这些未提交的日志复制到follower，但是不会主动提交它。
  - 未提交老日志判断方法：未提交日志的任期，比新leader当前的任期小，所以可以判断是之前从其他leader复制过来的。
  - 未提交日志提交的时机：新leader下一个日志提交的时候（日志任期等于leader当前任期），顺便再把这个未提交日志一起提交。这样就防止了已提交日志被回滚的情况。

## raft 与 zab

### 相同
- 都采用了多数派投票机制
- 都有leader角色，只有leader能写
- 都采用心跳探活

### 不同
- 角色不同
  - raft：leader、follower、candidate
  - zab：leader、follower、observer
- 阶段划分不同
  - raft：选举、日志复制 两个阶段
  - zab：选举、成员发现、数据同步、消息广播 四个阶段
- 投票方式
  - raft：每个任期只能投一票；有任期号、日志号两个概念
  - zab：
    - 可以投多次票；节点会随着收到的投票状态变更自己的投票，即如果有人投票比自己新，那就变票后再次发声
    - 有任期号、counter、节点唯一id（sid）三个概念，任期号+counter 构成 zxid，全局唯一且递增。zxid一样的情况下，sid大的拿选票；
- 日志流向
  - raft：所有日志都只能从leader流向follower
  - zab：晋升leader后，要从follower收集日志，生成初始提案集
- 其他
  - raft：新leader不会提交前任leader未提交的日志，得等下次本leader的日志提交时一起顺便提交
  - zab：新leader会先把前任未提交的日志提交。只后才能生成自己的日志。


# encoding: utf-8
# str = raw_input("please input a number:")
